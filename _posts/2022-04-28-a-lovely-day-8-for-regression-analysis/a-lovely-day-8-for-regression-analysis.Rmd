---
title: "A lovely day for regression analysis"
description: |
  Practicing regression analysis using fictional data.
author:
  - name: Juan David Acosta
date: 2022-04-28
categories:
  - Regression
  - Statistics
  - Data analysis
  - Data visualization
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

For today's blog post on this sunny Thursday in Toronto, I thought it would be great to get in some practice with regression analysis! What we'll be doing is the following: create fictional data that approximates a linear trend, visualize the data, fit a simple linear regression model to the data, visualize this fit using a line of best fit on our data visual, and make predictions using the model. Let's do this!

First, load in any libraries that are necessary to run our code. Whether or not I use it, I always find it to be good practice to load in the Tidyverse, since it is such a prominent collection of tidy libraries when it comes to data cleaning, analysis and visualization. I also find it a best practice to set a seed for reproducibility of random data; it may not be necessary in this case, but I like to set one just in case.

```{r, echo=TRUE}
# Load in necessary library.
library(tidyverse)

# Set seed.
set.seed(314159)
```

By this point in the blog, you should start to notice that I have a particularly favourite seed number (and I do love pie, mmm).

Now, with preliminaries out of the way, we can shift our focus to the data. For today's practice, let's say we want to predict a student's grade for the final exam in a particular course, let's say Economics 101, based on the amount of time in hours that they studied. The data we will record is thus a student's grade percentage on the final exam, and their corresponding number of hours that they spent studying for the final exam. Let's assume we recorded the grades for 20 students.

For the sake of simplicity, the data will be recorded in order from the lowest grade achieved on the final exam, to the highest grade.

```{r, echo=TRUE}
# Create a student id vector from one to 20.
student_id <- c(1:20)

# Create a vector for the final exam grades for 20 students in Economics 101,
# ordered from the lowest grade to the highest grade.
final_grades <- c(37, 47.5, 53.5, 57.5, 58, 60, 63.5, 64, 64, 65,
                  67, 69, 72, 72.5, 72.5, 77, 81, 85, 92, 95.5)

# Create a vector for the number of hours the 20 students from Economics 101
# studied for the final exam. These hours correspond positionally to the
# grades entered in the final_grades vector.
hours_studied <- c(0, 1, 1, 2, 3, 5, 5, 4, 4, 5,
                   7, 5, 7, 8, 10, 8, 9, 9, 11, 12)
```

This data would be nicer in a tibble (see, the Tidyverse always comes in handy!). Let's make it so!

```{r, echo=TRUE}
# Store final_grades and hours_studied as variables in a tibble.
grades_hours_tibble <- tibble(student_id, final_grades, hours_studied)

# View tibble as a kable.
grades_hours_kable <- 
  knitr::kable(grades_hours_tibble,
               format = "pipe",
               col.names = c("Student ID", "Final exam grades (%)",
                             "Number of hours studied"),
               caption = "Final exam grades (in %) and number of hours studied for students in Economics 101")
grades_hours_kable
```

From the fictional data, we can clearly see that there seems to be a strong correlation between the final exam grade a student received in Economics 101, and the number of hours they spent studying for the final exam. That is, the lower the number of hours they studied, the lower their mark will be, and conversely, the higher the number of hours they studied, the higher their mark will be. We want to be more rigorous about this, so we will now visualize the data to see if we can visually spot this linear correlation.

```{r, echo=TRUE}
# Create a scatter plot of the data.
grades_hours_plot <-
  grades_hours_tibble %>%
  ggplot(aes(x = hours_studied, y = final_grades)) +
  geom_point(colour = "blue") +
  labs(title = "Grades vs. hours studied for Economics 101 final exam",
       x = "Number of hours studied",
       y = "Final exam grade (in %)",
       caption = "Scatter plot.") +
  theme_minimal()
grades_hours_plot
```

The plot makes it visually clear that there seems to be a positive linear correlation between the grade a student received in the Economics 101 final exam and the number of hours that they studied for the final exam.

Now, we can fit a simple linear regression model to the data, since we claim that this model will give us the most approximate fit to the data.

```{r, echo=TRUE, include=TRUE}
# Fit data to simple linear regression model.
grades_hours_model <-
  lm(final_grades ~ hours_studied, data = grades_hours_tibble)

# Get summary of model.
summary(grades_hours_model)
```

As we can see from the raw output we obtain by using the `summary()` function on our model, the estimate for $\hat{\beta}_1$, which is the estimate for the slope coefficient, is `r round(grades_hours_model$coefficients[2], 3)`, which means that for every additional hour of study, the predicted grade will increase by 3.896 percentage points. $\hat{\beta}_1$ also has a p-value of approximately 0. At a significance level of $\alpha$ = 0.05, this means that the number of hours studied is significant in estimating the grade a student will receive on the final exam. We also have the estimate for $\hat{\beta}_0$ (estimate for the intercept), which is `r round(grades_hours_model$coefficients[1], 3)`, which means that if a student doesn't study at all, their grade is estimated as 45.078%. The adjusted R-squared value is `r round(summary(grades_hours_model)$adj.r.squared, 3)`, which means that we can have great confidence in the predictions made by our model, since the closer the adjusted R-squared value is to 1, the more reliable our model is at making predictions.

In summary, we can rely on our model to make predictions, and we have the coefficient estimates necessary to write an equation for predicting grades based on the number of hours spent studying. That equation is the following:

$$\hat{y} = 45.078 + 3.896x$$

Let's test it out! Consider a student that studies for eight hours. What is their predicted grade on the Economics 101 final exam?

```{r, echo=TRUE, include=TRUE}
# Predict final exam grade for student that studies for eight hours.
predicted_grade <- 45.078 + (3.896 * 8)

# Print the predicted grade.
predicted_grade
```

Thus, using our model, we predict that the student will receive a mark of approximately `r round(predicted_grade, 2)`% on their Economics 101 final exam.

Now, let's be very clear. This is a simplified model that does not take into account any other external factors that can affect a student's performance on a final exam, such as stress, physical and mental health, etc. Thus, just because our model predicts a student will get a mark of `r round(predicted_grade, 2)`% does not mean this will always be true.

Finally, we will see how close our model is to our actual data using a visualization.

```{r, echo=TRUE}
# Create scatter plot with line of best fit (our model).
grades_hours_plot_2 <-
  grades_hours_tibble %>%
  ggplot(aes(x = hours_studied, y = final_grades)) +
  geom_point(colour = "blue") +
  labs(title = "Grades vs. hours studied for Economics 101 final exam",
       x = "Number of hours studied",
       y = "Final exam grade (in %)",
       caption = "Scatter plot with line of best fit.") +
  geom_smooth(method = lm, se = FALSE) +
  theme_minimal()
grades_hours_plot_2
```

We can verify visually that our simple linear regression model was a very good fit for our data! Hope you had fun following along, and as with every blog that includes code on my website and any other section where my code has been explicitly provided or linked to, you are free to reproduce it yourself to try it out and even modify the data to try fitting models using different grades and study hours.

That's a wrap on today's post!
